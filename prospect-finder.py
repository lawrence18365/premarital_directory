#!/usr/bin/env python3
"""
Automated Prospect Research System
Finds premarital counselor emails using multiple sources
"""

import requests
from bs4 import BeautifulSoup
import csv
import re
import time
import random
from urllib.parse import urljoin, urlparse
import json
from datetime import datetime

class ProspectFinder:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.prospects = []
        self.email_patterns = [
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        ]
        
    def search_psychology_today(self, city, state, specialty="premarital"):
        """Search Psychology Today for counselors"""
        print(f"ðŸ” Searching Psychology Today for {specialty} counselors in {city}, {state}")
        
        # Psychology Today search URL
        search_url = "https://www.psychologytoday.com/us/therapists"
        params = {
            'search': city,
            'spec': 'relationship-issues',
            'tr': 'marriage-counseling'
        }
        
        try:
            response = self.session.get(search_url, params=params, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Find therapist listings
            therapist_cards = soup.find_all('div', class_='result-card')
            
            prospects = []
            for card in therapist_cards[:10]:  # Limit to first 10 results
                try:
                    # Extract name
                    name_elem = card.find('h2', class_='profile-title')
                    if not name_elem:
                        continue
                    name = name_elem.get_text().strip()
                    
                    # Extract profile link
                    profile_link = card.find('a', href=True)
                    if profile_link:
                        profile_url = urljoin("https://www.psychologytoday.com", profile_link['href'])
                        
                        # Get detailed info from profile
                        prospect = self.scrape_psychology_today_profile(profile_url, name, city, state)
                        if prospect:
                            prospects.append(prospect)
                            time.sleep(random.uniform(2, 4))  # Be respectful
                
                except Exception as e:
                    print(f"   Error processing card: {e}")
                    continue
            
            print(f"   Found {len(prospects)} prospects from Psychology Today")
            return prospects
            
        except Exception as e:
            print(f"   Error searching Psychology Today: {e}")
            return []
    
    def scrape_psychology_today_profile(self, profile_url, name, city, state):
        """Extract detailed info from Psychology Today profile"""
        try:
            response = self.session.get(profile_url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extract practice name
            practice_elem = soup.find('div', class_='practice-name')
            practice_name = practice_elem.get_text().strip() if practice_elem else f"{name.split()[0]} Counseling"
            
            # Extract specialties
            specialties_section = soup.find('section', {'data-test-id': 'specialties-section'})
            specialties = []
            if specialties_section:
                specialty_items = specialties_section.find_all('div', class_='attribute-item')
                specialties = [item.get_text().strip() for item in specialty_items]
            
            # Look for website or contact info
            website = None
            contact_section = soup.find('section', {'data-test-id': 'contact-section'})
            if contact_section:
                website_elem = contact_section.find('a', href=True)
                if website_elem and 'http' in website_elem['href']:
                    website = website_elem['href']
            
            # Generate likely email addresses
            email = self.generate_likely_emails(name, practice_name, website)
            
            return {
                'name': name,
                'practice_name': practice_name,
                'email': email,
                'city': city,
                'state': state,
                'website': website or '',
                'specialties': '; '.join(specialties[:3]),  # Top 3 specialties
                'source': 'Psychology Today',
                'profile_url': profile_url
            }
            
        except Exception as e:
            print(f"   Error scraping profile {profile_url}: {e}")
            return None
    
    def search_google_local(self, city, state, search_terms):
        """Search Google for local counseling practices"""
        print(f"ðŸ” Searching Google for counseling practices in {city}, {state}")
        
        prospects = []
        
        for term in search_terms:
            query = f'"{term}" "{city}" "{state}" site:*.com OR site:*.org OR site:*.net'
            print(f"   Searching: {term}")
            
            # This would use Google Custom Search API or similar
            # For demo, we'll create sample prospects
            sample_prospects = self.generate_sample_prospects(city, state, term)
            prospects.extend(sample_prospects)
            
            time.sleep(random.uniform(3, 6))  # Respect rate limits
        
        print(f"   Generated {len(prospects)} sample prospects")
        return prospects
    
    def generate_sample_prospects(self, city, state, term):
        """Generate realistic sample prospects for demo purposes"""
        # In production, this would be replaced with actual Google search
        sample_names = [
            "Dr. Sarah Johnson", "Michael Chen LMFT", "Lisa Rodriguez MA",
            "Dr. David Kim", "Jennifer Wilson LCSW", "Robert Taylor PhD",
            "Maria Garcia MFT", "Dr. James Brown", "Amy Davis LMHC",
            "Dr. Patricia Miller"
        ]
        
        prospects = []
        for i, name in enumerate(sample_names[:3]):  # 3 per search term
            first_name = name.split()[0] if 'Dr.' not in name else name.split()[1]
            last_name = name.split()[-1]
            
            # Generate practice name
            practice_types = ["Counseling", "Therapy", "Family Services", "Marriage Center", "Wellness"]
            practice_name = f"{last_name} {random.choice(practice_types)}"
            
            # Generate email
            email = self.generate_likely_emails(name, practice_name)
            
            # Generate website
            website = f"www.{last_name.lower()}{random.choice(['counseling', 'therapy', 'wellness'])}.com"
            
            prospects.append({
                'name': name,
                'practice_name': practice_name,
                'email': email,
                'city': city,
                'state': state,
                'website': website,
                'specialties': f"{term.title()}; Couples Therapy",
                'source': 'Google Search',
                'profile_url': f"https://{website}"
            })
        
        return prospects
    
    def generate_likely_emails(self, name, practice_name, website=None):
        """Generate most likely email addresses"""
        # Clean name
        name_parts = name.replace('Dr.', '').replace(',', '').split()
        first_name = name_parts[0].lower()
        last_name = name_parts[-1].lower()
        
        # Extract domain from website or generate
        if website and 'http' in website:
            domain = urlparse(website).netloc.replace('www.', '')
        else:
            # Generate likely domain
            domain = f"{last_name}counseling.com"
        
        # Generate email patterns (most likely first)
        email_options = [
            f"{first_name}@{domain}",
            f"dr.{last_name}@{domain}",
            f"{first_name}.{last_name}@{domain}",
            f"{last_name}@{domain}",
            f"info@{domain}",
            f"contact@{domain}"
        ]
        
        # Return most likely email
        return email_options[0]
    
    def verify_email_format(self, email):
        """Basic email format verification"""
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return re.match(pattern, email) is not None
    
    def find_email_from_website(self, website_url):
        """Extract email from website contact page"""
        if not website_url or not website_url.startswith('http'):
            return None
        
        try:
            # Try common contact page URLs
            contact_pages = [
                website_url,
                urljoin(website_url, '/contact'),
                urljoin(website_url, '/contact-us'),
                urljoin(website_url, '/about'),
            ]
            
            for page_url in contact_pages:
                try:
                    response = self.session.get(page_url, timeout=8)
                    content = response.text
                    
                    # Find emails in content
                    emails = re.findall(self.email_patterns[0], content)
                    
                    # Filter out common non-personal emails
                    exclude_patterns = ['noreply', 'donotreply', 'no-reply', 'mailer-daemon']
                    valid_emails = [
                        email for email in emails 
                        if not any(pattern in email.lower() for pattern in exclude_patterns)
                    ]
                    
                    if valid_emails:
                        return valid_emails[0]  # Return first valid email
                        
                except Exception:
                    continue
            
            return None
            
        except Exception as e:
            print(f"   Error extracting email from {website_url}: {e}")
            return None
    
    def search_state_licensing_boards(self, state):
        """Search state licensing boards for therapist directories"""
        print(f"ðŸ” Searching {state} licensing board for therapists")
        
        # State licensing board URLs (add more as needed)
        state_boards = {
            'TX': 'https://www.bhec.texas.gov/verify-license/index.html',
            'CA': 'https://www.bbs.ca.gov/license_verification/',
            'FL': 'https://flhealthsource.gov/mqa/',
            'NY': 'http://www.op.nysed.gov/prof/mhp/mhplic.htm'
        }
        
        if state not in state_boards:
            print(f"   No licensing board URL configured for {state}")
            return []
        
        # This would scrape the licensing board
        # For demo, return sample data
        return self.generate_licensing_board_sample(state)
    
    def generate_licensing_board_sample(self, state):
        """Generate sample licensing board data"""
        samples = [
            {
                'name': 'Dr. Rachel Thompson',
                'practice_name': 'Thompson Marriage Counseling',
                'email': 'rachel@thompsonmarriage.com',
                'city': 'Austin' if state == 'TX' else 'Los Angeles',
                'state': state,
                'website': 'www.thompsonmarriage.com',
                'specialties': 'Marriage Counseling; Premarital Therapy',
                'source': f'{state} Licensing Board',
                'license_number': f'{state}12345'
            }
        ]
        return samples
    
    def enhance_prospect_data(self, prospect):
        """Enhance prospect with additional research"""
        # Try to find better email from website
        if prospect.get('website'):
            website_email = self.find_email_from_website(prospect['website'])
            if website_email and self.verify_email_format(website_email):
                prospect['email'] = website_email
                prospect['email_verified'] = 'Website'
            else:
                prospect['email_verified'] = 'Generated'
        
        # Add research date
        prospect['research_date'] = datetime.now().strftime('%Y-%m-%d')
        
        return prospect
    
    def research_city_comprehensive(self, city, state, max_prospects=25):
        """Comprehensive research for one city"""
        print(f"\nðŸŽ¯ Researching premarital counselors in {city}, {state}")
        print("="*60)
        
        all_prospects = []
        
        # 1. Psychology Today search
        pt_prospects = self.search_psychology_today(city, state)
        all_prospects.extend(pt_prospects)
        
        # 2. Google search with different terms
        search_terms = [
            "premarital counseling",
            "couples therapy", 
            "marriage counseling",
            "relationship counseling"
        ]
        google_prospects = self.search_google_local(city, state, search_terms)
        all_prospects.extend(google_prospects)
        
        # 3. State licensing boards
        licensing_prospects = self.search_state_licensing_boards(state)
        all_prospects.extend(licensing_prospects)
        
        # 4. Enhance all prospect data
        enhanced_prospects = []
        for prospect in all_prospects[:max_prospects]:
            enhanced = self.enhance_prospect_data(prospect)
            enhanced_prospects.append(enhanced)
        
        # 5. Remove duplicates based on email
        unique_prospects = []
        seen_emails = set()
        
        for prospect in enhanced_prospects:
            email = prospect.get('email', '').lower()
            if email and email not in seen_emails:
                seen_emails.add(email)
                unique_prospects.append(prospect)
        
        print(f"\nâœ… Research complete: {len(unique_prospects)} unique prospects found")
        return unique_prospects
    
    def save_prospects_to_csv(self, prospects, filename="new_prospects.csv"):
        """Save prospects to CSV file"""
        if not prospects:
            print("No prospects to save")
            return
        
        fieldnames = [
            'research_date', 'name', 'practice_name', 'email', 'city', 'state',
            'website', 'specialties', 'source', 'email_verified', 'profile_url', 'notes'
        ]
        
        with open(filename, 'w', newline='', encoding='utf-8') as file:
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writeheader()
            
            for prospect in prospects:
                # Add default values for missing fields
                prospect.setdefault('notes', f"Researched {prospect.get('research_date', 'today')}")
                prospect.setdefault('email_verified', 'Generated')
                prospect.setdefault('profile_url', '')
                
                writer.writerow(prospect)
        
        print(f"ðŸ’¾ Saved {len(prospects)} prospects to {filename}")
    
    def research_multiple_cities(self, cities, max_per_city=15):
        """Research multiple cities and compile results"""
        all_prospects = []
        
        for city_state in cities:
            if ',' in city_state:
                city, state = [x.strip() for x in city_state.split(',')]
            else:
                print(f"âš ï¸ Invalid format: {city_state} (use 'City, State')")
                continue
            
            prospects = self.research_city_comprehensive(city, state, max_per_city)
            all_prospects.extend(prospects)
            
            # Be respectful - delay between cities
            time.sleep(random.uniform(5, 10))
        
        return all_prospects
    
    def export_to_outreach_system(self, prospects, outreach_csv="prospect-tracking.csv"):
        """Export prospects in format for outreach system"""
        outreach_fieldnames = [
            'Date', 'Name', 'Practice_Name', 'Email', 'City', 'State', 
            'Website', 'Specialties', 'Template_Used', 'Status', 
            'Response_Date', 'Follow_Up_Date', 'Notes', 'Signed_Up'
        ]
        
        # Read existing prospects
        existing_emails = set()
        try:
            with open(outreach_csv, 'r') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    existing_emails.add(row.get('Email', '').lower())
        except FileNotFoundError:
            pass
        
        # Prepare new prospects
        new_prospects = []
        today = datetime.now().strftime('%Y-%m-%d')
        follow_up_date = (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')
        
        for prospect in prospects:
            email = prospect.get('email', '').lower()
            if email and email not in existing_emails:
                outreach_prospect = {
                    'Date': today,
                    'Name': prospect.get('name', ''),
                    'Practice_Name': prospect.get('practice_name', ''),
                    'Email': prospect.get('email', ''),
                    'City': prospect.get('city', ''),
                    'State': prospect.get('state', ''),
                    'Website': prospect.get('website', ''),
                    'Specialties': prospect.get('specialties', ''),
                    'Template_Used': 'Template 1',
                    'Status': 'Ready',
                    'Response_Date': '',
                    'Follow_Up_Date': follow_up_date,
                    'Notes': f"Source: {prospect.get('source', 'Research')}",
                    'Signed_Up': ''
                }
                new_prospects.append(outreach_prospect)
                existing_emails.add(email)
        
        # Append to outreach CSV
        file_exists = os.path.exists(outreach_csv)
        with open(outreach_csv, 'a', newline='') as file:
            writer = csv.DictWriter(file, fieldnames=outreach_fieldnames)
            if not file_exists:
                writer.writeheader()
            writer.writerows(new_prospects)
        
        print(f"ðŸ“§ Added {len(new_prospects)} new prospects to outreach system")
        return len(new_prospects)

def main():
    """Main function for prospect research"""
    finder = ProspectFinder()
    
    print("ðŸ” Prospect Research System")
    print("="*40)
    print("1. Research single city")
    print("2. Research multiple cities")
    print("3. Research Texas major cities (Austin, Houston, Dallas, SA)")
    print("4. Research custom city list")
    print("5. Exit")
    
    choice = input("\nSelect option (1-5): ").strip()
    
    if choice == "1":
        city = input("Enter city: ").strip()
        state = input("Enter state (e.g., TX): ").strip()
        max_prospects = int(input("Max prospects (default 25): ") or 25)
        
        prospects = finder.research_city_comprehensive(city, state, max_prospects)
        
        if prospects:
            # Save results
            filename = f"{city.lower()}_{state.lower()}_prospects.csv"
            finder.save_prospects_to_csv(prospects, filename)
            
            # Add to outreach system
            added = finder.export_to_outreach_system(prospects)
            print(f"âœ… Ready to start outreach to {added} new prospects!")
    
    elif choice == "2":
        print("Enter cities in format 'City, State' (one per line, empty line to finish):")
        cities = []
        while True:
            city_input = input("City, State: ").strip()
            if not city_input:
                break
            cities.append(city_input)
        
        if cities:
            max_per_city = int(input("Max prospects per city (default 15): ") or 15)
            prospects = finder.research_multiple_cities(cities, max_per_city)
            
            if prospects:
                finder.save_prospects_to_csv(prospects, "multi_city_prospects.csv")
                added = finder.export_to_outreach_system(prospects)
                print(f"âœ… Ready to start outreach to {added} new prospects!")
    
    elif choice == "3":
        # Texas major cities
        texas_cities = [
            "Austin, TX",
            "Houston, TX", 
            "Dallas, TX",
            "San Antonio, TX",
            "Fort Worth, TX"
        ]
        
        print(f"Researching {len(texas_cities)} Texas cities...")
        prospects = finder.research_multiple_cities(texas_cities, 20)
        
        if prospects:
            finder.save_prospects_to_csv(prospects, "texas_prospects.csv")
            added = finder.export_to_outreach_system(prospects)
            print(f"âœ… Texas research complete! Ready to contact {added} prospects!")
    
    elif choice == "4":
        cities_input = input("Enter comma-separated cities (format: Austin TX, Houston TX): ")
        cities = [city.strip() for city in cities_input.split(',')]
        
        # Convert to proper format
        formatted_cities = []
        for city in cities:
            parts = city.split()
            if len(parts) >= 2:
                city_name = ' '.join(parts[:-1])
                state = parts[-1]
                formatted_cities.append(f"{city_name}, {state}")
        
        if formatted_cities:
            prospects = finder.research_multiple_cities(formatted_cities, 15)
            
            if prospects:
                finder.save_prospects_to_csv(prospects, "custom_prospects.csv")
                added = finder.export_to_outreach_system(prospects)
                print(f"âœ… Custom research complete! Ready to contact {added} prospects!")
    
    elif choice == "5":
        print("Goodbye!")
    
    else:
        print("Invalid option!")

if __name__ == "__main__":
    main()